Ncluster_max <- 10
# Number of current clusters (i.e., tables that all segments might sit)
Nattr <- 1
# Cluster spawning coefficient
alpha <- 1
# Cluster params
cmu <- rep(mu0, Ncluster_max)
cvar <- var0 # we don't actually use Inverse Wishart Prior because in the simplest case, we just assume a fixed variance for each cluster
ctau <- solve(cvar)
# We create an "attribution" object which indicates the cluster that each segment belongs to (this is for the second CRP
# where we group the segments into the cluster
attr <- matrix(, nrow=nrow(x_mat), ncol=Ncp_max) # 10 is the maximum number of segments in each time series
# Assign the initial cluster for each segment, just assign to the same cluster for now
attr[, 1] <- 1
attr[, 2] <- 1
# For the number of changepoints, Nattr_cp is the maximum number of changepoints (tables).
# Each time, a time series will be asked if they want to increase this number (open a new table).
Nattr_cp <- max(attr, na.rm=T)
alpha_cp <- 2 # the rate at which the time series will decide to open a larger number of changepoints that other time series has not yet considered
# We place random changepoints among the time series
# the actual positions of the changepoints are not important
# because we will change them anyway. What matters is many time series will originally sit at
# the same table. This influences the probability to open new table.
for (ts_index in 1:length(x_cut))
{
ts_length <- length(x_cut[[ts_index]])
change_at <- sample(2:ts_length-1, 1)
# cp[ts_index] <- list(append(cp[[ts_index]], change_at))
cp[ts_index] <- list(change_at)
}
# == End of Initialization of the Dirichlet Process ==
# ==
debugSource("~/Documents/anomaly-detection-ngsim/lanechange/vwp_test3cp.R")
p_this_cp_is_correct * p_sit_with_others_cp
debugSource("~/Documents/anomaly-detection-ngsim/lanechange/vwp_test3cp.R")
cp_seatings
cp
cp_seatings
length(cp[1])
length(cp[2])
cp
length(cp[[1]])
source("~/Documents/anomaly-detection-ngsim/lanechange/vwp_lib.R")
debugSource("~/Documents/anomaly-detection-ngsim/lanechange/vwp_test3cp.R")
cp_seatings
debugSource("~/Documents/anomaly-detection-ngsim/lanechange/vwp_test3cp.R")
# This is an example where we try to detect the "slopes"
# ================
#
# GENERATE A SAMPLE SIGNAL
#
# =================
# source("~/Documents/anomaly-detection-ngsim/lanechange/vwp_lib.R")
source("~/anomaly-detection-ngsim/lanechange/vwp_lib.R")
default_ts_length <- 20
x_mat <- matrix(, nrow=0, ncol = default_ts_length)
slopes <- c(1,-3,-1,3,-1,-3,1,3)
zero_period <- 12
rise_period <- 5
for (s in 1:20) # total number of time series to generate
{
slope_start_from <- sample(1:4, size=1, replace=T)
x_sample <- rep(0, default_ts_length)
for (t in 1:length(x_sample))
{
noise = rnorm(1,mean=0,sd=0.2)
value_at_t <- 0
if ((t>1) & (t<=5))
{
value_at_t <- x_sample[t-1] + slopes[slope_start_from]
} else if ((t>5) & (t<=10))
{
value_at_t <- x_sample[t-1] + slopes[slope_start_from + 1]
} else if ((t>10) & (t<=15))
{
value_at_t <- x_sample[t-1] + slopes[slope_start_from + 2]
} else if (t>15)
{
value_at_t <- x_sample[t-1] + slopes[slope_start_from + 3]
}
x_sample[t] <- value_at_t + noise
}
x_mat <- rbind(x_mat, x_sample)
}
plot(x_sample)
# ================
#
# DEFINE A BASIS FUNCTION
#
# =================
basis = 1:30
plot(basis)
plot(x_mat[1,])
plot(x_mat[2,])
# This is an example where we try to detect the "slopes"
# ================
#
# GENERATE A SAMPLE SIGNAL
#
# =================
# source("~/Documents/anomaly-detection-ngsim/lanechange/vwp_lib.R")
source("~/anomaly-detection-ngsim/lanechange/vwp_lib.R")
default_ts_length <- 20
x_mat <- matrix(, nrow=0, ncol = default_ts_length)
slopes <- c(1,-3,-1,3,-1,-3,1,3)
zero_period <- 12
rise_period <- 5
# 20 time series that has 3 changepoints
for (s in 1:20) # total number of time series to generate
{
slope_start_from <- sample(1:4, size=1, replace=T)
x_sample <- rep(0, default_ts_length)
for (t in 1:length(x_sample))
{
noise = rnorm(1,mean=0,sd=0.2)
value_at_t <- 0
if ((t>1) & (t<=5))
{
value_at_t <- x_sample[t-1] + slopes[slope_start_from]
} else if ((t>5) & (t<=10))
{
value_at_t <- x_sample[t-1] + slopes[slope_start_from + 1]
} else if ((t>10) & (t<=15))
{
value_at_t <- x_sample[t-1] + slopes[slope_start_from + 2]
} else if (t>15)
{
value_at_t <- x_sample[t-1] + slopes[slope_start_from + 3]
}
x_sample[t] <- value_at_t + noise
}
x_mat <- rbind(x_mat, x_sample)
}
# 20 timeseries that have 2 changepoints
for (s in 21:40) # total number of time series to generate
{
slope_start_from <- sample(1:4, size=1, replace=T)
x_sample <- rep(0, default_ts_length)
for (t in 1:length(x_sample))
{
noise = rnorm(1,mean=0,sd=0.2)
value_at_t <- 0
if ((t>1) & (t<=12))
{
value_at_t <- x_sample[t-1] + slopes[slope_start_from]
} else if (t>12)
{
value_at_t <- x_sample[t-1] + slopes[slope_start_from + 2]
}
x_sample[t] <- value_at_t + noise
}
x_mat <- rbind(x_mat, x_sample)
}
plot(x_sample)
dim(x_mat)
# == Initialization of the Dirichlet Process ==
# ==
# Cluster base distribution
mu0 <- 1.0
var0 <- 1.0
tau0 <- solve(var0)
# Measurement variance
vary <- 0.05
tauy <- solve(vary)
# All the changepoints
cp <- list()
# We create an x_cut object which contains all the segments when cutting the x_mat time series
x_cut <- list()
# Originally, this object will just be a duplicate of x_mat, all the original time series not cut
for (ts in 1:nrow(x_mat))
{
x_cut <- append(x_cut, list(x_mat[ts,]))
}
# The number of maximum segments one time series can have
Ncp_max <- 10
# The maximum number of clusters each segment can take
Ncluster_max <- 10
# Number of current clusters (i.e., tables that all segments might sit)
Nattr <- 1
# Cluster spawning coefficient
alpha <- 1
# Cluster params
cmu <- rep(mu0, Ncluster_max)
cvar <- var0 # we don't actually use Inverse Wishart Prior because in the simplest case, we just assume a fixed variance for each cluster
ctau <- solve(cvar)
# We create an "attribution" object which indicates the cluster that each segment belongs to (this is for the second CRP
# where we group the segments into the cluster
attr <- matrix(, nrow=nrow(x_mat), ncol=Ncp_max) # 10 is the maximum number of segments in each time series
# Assign the initial cluster for each segment, just assign to the same cluster for now
attr[, 1] <- 1
attr[, 2] <- 1
# For the number of changepoints, Nattr_cp is the maximum number of changepoints (tables).
# Each time, a time series will be asked if they want to increase this number (open a new table).
Nattr_cp <- max(attr, na.rm=T)
alpha_cp <- 2 # the rate at which the time series will decide to open a larger number of changepoints that other time series has not yet considered
# We place random changepoints among the time series
# the actual positions of the changepoints are not important
# because we will change them anyway. What matters is many time series will originally sit at
# the same table. This influences the probability to open new table.
for (ts_index in 1:length(x_cut))
{
ts_length <- length(x_cut[[ts_index]])
change_at <- sample(2:ts_length-1, 1)
# cp[ts_index] <- list(append(cp[[ts_index]], change_at))
cp[ts_index] <- list(change_at)
}
# == End of Initialization of the Dirichlet Process ==
# ==
# == Begin the iterative procedure ==
# == >> << ==
max_big_iter <- 10
for (big_iter in 1:max_big_iter)
{
all_pah <- list()
cat('Iteration ', big_iter, '\n')
print('Optimizing changepoints...')
pb = txtProgressBar(min = 0, max = dim(x_mat)[1], initial = 0)
for (ts_index in 1:(dim(x_mat)[1]))
{
setTxtProgressBar(pb, ts_index)
# cat("\n ==========")
# cat("\n Processing time series ", ts_index)
# == Step 1: Setting a new number of changepoints for the current TS ==
# Get the seatings of each number of changepoints
Ncp_of_each_ts <- get_number_of_changepoints(cp)
cp_seatings <- n_customers_at_each_table_cp(Ncp_of_each_ts, Ncp_max)
# We first unseat the current time series
table_of_current_ts <- Ncp_of_each_ts[ts_index]
cp_seatings[table_of_current_ts] <- cp_seatings[table_of_current_ts] - 1
# We run a fake Chinese Restaurant Process for the current time series to choose
# the number of changepoints cp_table
ts_length <- length(x_mat[ts_index,])
pah <- precalculate_a_and_homogeneity(x_mat[ts_index,], basis, vary)
all_pah[ts_index] <- list(pah) # We store all precalculated values so that the clustering can re use these values
p_table_cp <- rep(0, Nattr_cp+1)
proposed_cp <- list()
proposed_cluster_attr <- list()
for (cp_table in 1:(Nattr_cp+1))
{
if (cp_table <= Nattr_cp)
{
# Calculate proba that the time series will open a higher number of changepoints that
# other time series yet to consider
nk_cp <- cp_seatings[cp_table]
N_seatings_cp <- sum(cp_seatings)
p_sit_with_others_cp <- nk_cp / (N_seatings_cp - 1 + alpha_cp)
# We find the optimal segmentation given the number of changepoints equal cp_table
part <- find_most_likely_partitioning_of_a_time_series(ts_length, cp_table, cmu, ctau, Nattr, pah)
p_this_cp_is_correct <- exp(part$lp) # given the maximum number of changepoints and the cluster means
p_table_cp[cp_table] <- p_this_cp_is_correct * p_sit_with_others_cp
# cat("\n Likelihood of CRP: ", p_sit_with_others_cp)
# cat("\n Likelihood of CP: ", part$lp)
# cat("\n Proposed CP: ", part$cp)
proposed_cp <- append(proposed_cp, list(part$cp))
proposed_cluster_attr <- append(proposed_cluster_attr, list(part$attr))
} else {
# Calculate proba that the time series will open a higher number of changepoints that
# other time series yet to consider
p_open_a_new_table_cp <- alpha / (N_seatings_cp - 1 + alpha_cp)
part <- find_most_likely_partitioning_of_a_time_series(ts_length, cp_table, cmu, ctau, Nattr, pah)
p_this_cp_is_correct <- exp(part$lp) # given the maximum number of changepoints and the cluster means
p_table_cp[cp_table] <- p_this_cp_is_correct * p_open_a_new_table_cp
if (p_table_cp[cp_table] < 0)
{
print("Negative probability?")
}
# cat("\n Likelihood of CRP: ", p_open_a_new_table_cp)
# cat("\n Likelihood of CP: ", part$lp)
# cat("\n Proposed CP: ", part$cp)
proposed_cp <- append(proposed_cp, list(part$cp))
proposed_cluster_attr <- append(proposed_cluster_attr, list(part$attr))
}
} # end of looping through all the tables
p_table_cp <- p_table_cp / sum(p_table_cp)
#cat("\n Table assignment proba: ", p_table_cp)
# Sample the new table for this customer to sit (including opening new one)
table_to_sit_cp <- sample(1:(Nattr_cp+1), 1, replace=T, prob=p_table_cp)
#cat("\n Choosing the number of changepoints as ", table_to_sit_cp)
cp[ts_index] <- list(proposed_cp[[table_to_sit_cp]])
if (table_to_sit_cp == (Nattr_cp + 1))
{
Nattr_cp <- Nattr_cp + 1
#cat("\n Opened a new number of changepoints. Maximum changepoints is now ", Nattr_cp)
} else {
#cat("\n Keep the same number of changepoints. Maximum changepoints is now ", Nattr_cp)
}
# Assigning the cluster attribution
best_cluster_attr <- proposed_cluster_attr[[table_to_sit_cp]]
attr[ts_index, 1:length(best_cluster_attr)] <- best_cluster_attr
# == End of step 1: Setting a new number of changepoints for the current TS ==
}
close(pb)
# == Step 2: Assigning cluster for each segment ==
# NOTICE: Consider integrating this loop into Step 1's loop to have better handling of memory
# We can cut our original time series according to cp
xa_cut <- cut_x(x_mat, cp, basis, all_pah)
x_cut <- xa_cut$x_cut
a_cut <- xa_cut$a_cut
max_iter <- 50 # max iter per clustering attempt
pb2 = txtProgressBar(min = 0, max = max_iter, initial = 0)
print('Clustering segments...')
for (iter in 1:max_iter)
{
setTxtProgressBar(pb2, iter)
for (ts_index in 1:length(x_cut))
{
for (segment_index in 1:length(a_cut[[ts_index]]))
{
seatings <- n_customers_at_each_table(attr)
a_of_customer <- a_cut[[ts_index]][[segment_index]]
table_of_current_customer <- attr[ts_index, segment_index]
# First we un-seat the current customer (or segment) from his table
seatings[table_of_current_customer] <- seatings[table_of_current_customer] - 1
attr[ts_index,segment_index] <- -1
if (seatings[table_of_current_customer] == 0)
{
# If the unseated customer turns out to be the last one sitting at that table, we remove the table via a two steps process
# First, we swap the (just emptied) table with the last table (i.e., table Nattr) by reassigning the seats of all customers sitting there
# Then we let Nattr - 1 so the last empty table is gone
attr[attr==Nattr] <- table_of_current_customer # resitting all the customers at the last table
seatings[table_of_current_customer] <- seatings[Nattr] # swap the number of customers of the two tables being swapped
Nattr <- Nattr - 1 # remove the last (now empty) table
}
# Now run the Chinese Restaurant Process
# Each cluster will try to "engulf" the segment's a and see its mean and variance shifted
# to posterior mean and variance values
# This variable holds the proba of all tables that the customer is going to sit in
p_sit_at_table <- rep(0, Nattr+1)
for (table in 1:(Nattr+1))
{
if (table <= Nattr)
{
# Sit with others
# Calculate posterior values
# The current mean and variance
# current_mean <- mu0 # actually not used
current_var <- var0 # use the fixed variance for cluster in this version of code
# a posterior with inverse-Wishart prior and likelihood from the data seems like a better choice
nk <- seatings[table]
tauk <- solve(current_var)
# Run a loop to calculate the sum of data of the current cluster
cluster_sum <- 0
for (aux_ts_index in 1:length(x_cut))
{
for (aux_segment_index in 1:length(x_cut[[aux_ts_index]]))
{
if (attr[aux_ts_index,aux_segment_index] == table)
{
cluster_sum <- cluster_sum + as.vector(a_cut[[aux_ts_index]][[aux_segment_index]])
}
}
} # Calculation of cluster_sum completed
taup <- nk * tauk + tau0
sigp <- solve(taup)
new_mean <- sigp * (tauk * cluster_sum + mu0 * tau0)
cmu[table] <- new_mean
new_var <- sigp + vary
new_sd <- sqrt(new_var)
N_seatings <- sum(seatings)
# The likelihood of "sitting at an occupied table" is
p_sit_at_occupied <- nk / (N_seatings - 1 + alpha)
# Replace a_of_customer is the line below if we want to also account for the homogeneity of the measurements
# here it works like the most basic HDP-GMM (that doesn't even account for )
p_sit_at_table_k <- p_sit_at_occupied * dnorm(a_of_customer, mean=new_mean, sd=new_sd)
p_sit_at_table[table] <- p_sit_at_table_k
} else
{
# Open a new table
p_sit_at_unoccupied <- alpha / (N_seatings - 1 + alpha)
new_sd <- sqrt(vary + var0)
p_sit_at_table_Kplus1 <- p_sit_at_unoccupied * dnorm(a_of_customer, mean=mu0, sd=new_sd)
p_sit_at_table[table] <- p_sit_at_table_Kplus1
}
} # end of loop through all tables
# Normalize the p_sit_at_table
p_sit_at_table <- p_sit_at_table / sum(p_sit_at_table)
# Sample the new table for this customer to sit (including opening new one)
table_to_sit <- sample(1:(Nattr+1), 1, replace=T, prob=p_sit_at_table)
attr[ts_index,segment_index] <- table_to_sit
if (table_to_sit == Nattr+1)
{
# The customer has decided upon opening a new table
Nattr <- Nattr + 1 # increase the number of tables (i.e., clusters) by 1
}
}
}
} # clustering loop
close(pb2)
} # end of big iter
source("~/Documents/anomaly-detection-ngsim/lanechange/vwp_test4cp.R")
source("~/Documents/anomaly-detection-ngsim/lanechange/vwp_test4cp.R")
# This is an example where we try to detect the "slopes"
# ================
#
# GENERATE A SAMPLE SIGNAL
#
# =================
# source("~/Documents/anomaly-detection-ngsim/lanechange/vwp_lib.R")
source("~/anomaly-detection-ngsim/lanechange/vwp_lib.R")
default_ts_length <- 20
source("~/Documents/anomaly-detection-ngsim/lanechange/vwp_test4cp.R")
source("~/Documents/anomaly-detection-ngsim/lanechange/vwp_test4cp.R")
source("~/Documents/anomaly-detection-ngsim/lanechange/vwp_test4cp.R")
source("~/Documents/anomaly-detection-ngsim/lanechange/vwp_test4cp.R")
source("~/Documents/anomaly-detection-ngsim/lanechange/vwp_test4cp.R")
source("~/Documents/anomaly-detection-ngsim/lanechange/vwp_test4cp.R")
source("~/Documents/anomaly-detection-ngsim/lanechange/vwp_test4mix.R")
setwd("~/Documents/anomaly-detection-ngsim/lanechange")
cmu
attr
cmu[attr[1,]]
cmu[attr[30,]]
plot(x_mat[1,])
cp[[30]]
attr_cp
Nattr_cp
Ncp_of_each_ts <- get_number_of_changepoints(cp)
Ncp_of_each_ts
cp_seatings <- n_customers_at_each_table_cp(Ncp_of_each_ts, Ncp_max)
cp_seatings
source("~/Documents/anomaly-detection-ngsim/lanechange/vwp_visualize.R")
visualize_belief(x_mat, cp, cmu, attr, 30)
visualize_belief(x_mat, cp, cmu, attr, 30)
source("~/Documents/anomaly-detection-ngsim/lanechange/vwp_visualize.R")
visualize_belief(x_mat, cp, cmu, attr, 30)
source("~/Documents/anomaly-detection-ngsim/lanechange/vwp_visualize.R")
source("~/Documents/anomaly-detection-ngsim/lanechange/vwp_visualize.R")
visualize_belief(x_mat, cp, cmu, attr, 30)
source("~/Documents/anomaly-detection-ngsim/lanechange/vwp_visualize.R")
visualize_belief(x_mat, cp, cmu, attr, 30)
source("~/Documents/anomaly-detection-ngsim/lanechange/vwp_visualize.R")
source("~/Documents/anomaly-detection-ngsim/lanechange/vwp_visualize.R")
visualize_belief(x_mat, cp, cmu, attr, 30)
source("~/Documents/anomaly-detection-ngsim/lanechange/vwp_visualize.R")
visualize_belief(x_mat, cp, cmu, attr, 30)
plot(x_mat[30,])
source("~/Documents/anomaly-detection-ngsim/lanechange/vwp_visualize.R")
source("~/Documents/anomaly-detection-ngsim/lanechange/vwp_visualize.R")
explain_belief(x_mat, cp, cmu, attr, 10)
round(1.99)
source("~/Documents/anomaly-detection-ngsim/lanechange/vwp_visualize.R")
round(1.99)
source("~/Documents/anomaly-detection-ngsim/lanechange/vwp_visualize.R")
explain_belief(x_mat, cp, cmu, attr, 30)
source("~/Documents/anomaly-detection-ngsim/lanechange/vwp_visualize.R")
explain_belief(x_mat, cp, cmu, attr, 30)
source("~/Documents/anomaly-detection-ngsim/lanechange/vwp_visualize.R")
explain_belief(x_mat, cp, cmu, attr, 30)
source("~/Documents/anomaly-detection-ngsim/lanechange/vwp_visualize.R")
explain_belief(x_mat, cp, cmu, attr, 30)
Nattr_cp
hist(Ncp_of_each_ts)
cp_seatings
Ncp_of_each_ts
plot(x_mat[27,])
plot(x_mat[22,])
source("~/Documents/anomaly-detection-ngsim/lanechange/vwp_visualize.R")
source("~/Documents/anomaly-detection-ngsim/lanechange/vwp_visualize.R")
explain_overall(Nattr, Nattr_cp, attr)
source("~/Documents/anomaly-detection-ngsim/lanechange/vwp_visualize.R")
explain_overall(Nattr, Nattr_cp, attr)
attr
max(attr, na.rm=TRUE)
max(attr, na.rm=FAlSE)
max(attr, na.rm=F)
max(attr, na.rm=T)
min(attr, na.rm=T)
hist(attr, na.rm=T)
attr
attr
as.vector(attr)
as.vector(attr)[!is.na(attr)]
hist(as.vector(attr)[!is.na(attr)])
source("~/Documents/anomaly-detection-ngsim/lanechange/vwp_visualize.R")
table(as.vector(attr)[!is.na(attr)]))
table(as.vector(attr)[!is.na(attr)])
barplot(table(as.vector(attr)[!is.na(attr)]))
f <- table(as.vector(attr)[!is.na(attr)])
names(f) <- cmu[names(f)]
f
cmu
names(f)
names(f) <- cmu[1:length(f)]
f
source("~/Documents/anomaly-detection-ngsim/lanechange/vwp_visualize.R")
source("~/Documents/anomaly-detection-ngsim/lanechange/vwp_visualize.R")
explain_overall(Nattr, Nattr_cp, attr)
source("~/Documents/anomaly-detection-ngsim/lanechange/vwp_visualize.R")
explain_overall(Nattr, Nattr_cp, attr)
visualize_belief(x_mat, cp, cmu, attr, 25)
explain_belief(x_mat, cp, cmu, attr, 25)
explain_belief(x_mat, cp, cmu, attr, 21)
attr
source("~/Documents/anomaly-detection-ngsim/lanechange/vwp_visualize.R")
source("~/Documents/anomaly-detection-ngsim/lanechange/vwp_test4mix.R")
explain_overall(Nattr, Nattr_cp, attr)
source("~/Documents/anomaly-detection-ngsim/lanechange/vwp_visualize.R")
explain_overall(Nattr, Nattr_cp, attr)
explain_belief(x_mat, cp, cmu, attr, 20)
explain_belief(x_mat, cp, cmu, attr, 10)
explain_belief(x_mat, cp, cmu, attr, 21)
explain_belief(x_mat, cp, cmu, attr, 22)
explain_belief(x_mat, cp, cmu, attr, 23)
explain_belief(x_mat, cp, cmu, attr, 24)
explain_belief(x_mat, cp, cmu, attr, 25)
explain_belief(x_mat, cp, cmu, attr, 26)
explain_belief(x_mat, cp, cmu, attr, 30)
source("~/Documents/anomaly-detection-ngsim/lanechange/vwp_test4mix.R")
source("~/Documents/anomaly-detection-ngsim/lanechange/vwp_visualize.R")
explain_overall(Nattr, Nattr_cp, attr)
explain_belief(x_mat, cp, cmu, attr, 27)
explain_belief(x_mat, cp, cmu, attr, 2)
